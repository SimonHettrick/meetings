\documentclass[11pt, oneside]{amsart}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{color}
\usepackage{dcolumn}
\usepackage{float}
\usepackage{graphicx}
\usepackage[latin9]{inputenc}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{subfigure} 
\usepackage{psfrag}
\usepackage{tabularx}
\usepackage[hyphens]{url}
\usepackage{wrapfig}
\usepackage{longtable}
\usepackage{verbatim}

\usepackage{enumitem}
\setlist{leftmargin=7mm}
 
%\setcounter{secnumdepth}{3}
%\setcounter{tocdepth}{3}


\usepackage[bookmarks, bookmarksopen, bookmarksnumbered]{hyperref}
\usepackage[all]{hypcap}
\urlstyle{rm}

\definecolor{orange}{rgb}{1.0,0.3,0.0}
\definecolor{violet}{rgb}{0.75,0,1}
\definecolor{darkgreen}{rgb}{0,0.6,0}
\definecolor{cyan}{rgb}{0.2,0.7,0.7}
\definecolor{blueish}{rgb}{0.2,0.2,0.8}

\newcommand{\todo}[1]{{\color{blue}$\blacksquare$~\textsf{[TODO: #1]}}}
\newcommand{\note}[1]{ {\textcolor{blueish}    { ***Note:      #1 }}}
\newcommand{\katznote}[1]{ {\textcolor{magenta}    { ***Dan:      #1 }}}
\newcommand{\gabnote}[1]{ {\textcolor{cyan}    { ***Gabrielle:     #1 }}}
\newcommand{\nchnote}[1]{  {\textcolor{orange}      { ***Neil: #1 }}}
\newcommand{\manishnote}[1]{  {\textcolor{violet}     { ***Manish: #1 }}}
\newcommand{\davidnote}[1]{  {\textcolor{darkgreen}      { ***David: #1 }}}
\newcommand{\colinnote}[1]{ {\textcolor{red}    {***Colin: #1 }}}
\newcommand{\choinote}[1]{ {\textcolor{orange}    {***Choi: #1 }}}

% Don't use tt font for urls
\urlstyle{rm}

% 15 characters / 2.5 cm => 100 characters / line
% Using 11 pt => 94 characters / line
\setlength{\paperwidth}{216 mm}
% 6 lines / 2.5 cm => 55 lines / page
% Using 11pt => 48 lines / pages
\setlength{\paperheight}{279 mm}
\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}
% You can use a baselinestretch of down to 0.9
\renewcommand{\baselinestretch}{0.96}

\sloppypar

\begin{document}

\title[]{Report on the Second Workshop on Sustainable Software for Science: Practice and Experiences (WSSSPE2)} 

\author{TBD by contributions \\{\scriptsize\today \quad  (Due:  $\backsim$ April 1)}}
%\author{Daniel S. Katz$^{(1)}$, Gabrielle Allen$^{(2)}$, Neil Chue Hong$^{(3)}$, \\
%Karen Cranston$^{(4)}$, Manish Parashar$^{(5)}$, David Proctor$^{(6)}$, \\
%Matthew Turk$^{(2)}$, Colin C. Venters$^{(7)}$, Nancy Wilkins-Diehr$^{(8)}$,
%Richard Littauer$^{(9)}$,
%Miguel de Val-Borro$^{(10)}$, 
%Sou-Cheng T. Choi$^{(11)}$}
%
%\thanks{{}$^{(1)}$ National Science Foundation, Arlington, VA, USA; Computation Institute, University of Chicago \& Argonne National Laboratory, Chicago, IL, USA}
%
%\thanks{{}$^{(2)}$ University of Illinois, Champaign, IL, USA}
%
%\thanks{{}$^{(3)}$ Software Sustainability Institute, University of Edinburgh, Edinburgh, UK}
%  
%\thanks{{}$^{(4)}$ National Evolutionary Synthesis Center, Durham, NC, USA}
%
%\thanks{{}$^{(5)}$ Rutgers Discovery Informatics Institute, Rutgers University, New Brunswick, NJ, USA}
%
%\thanks{{}$^{(6)}$ International Consortium of Research Staff Associations, Dublin, Ireland}
%
%\thanks{{}$^{(7)}$ University of Huddersfield, School of Computing and Engineering, Huddersfield, UK}
%
%\thanks{{}$^{(8)}$ University of California-San Diego, San Diego, CA, USA}
%
%\thanks{{}$^{(9)}$ Saarland University, Saarbr\"{u}cken, Germany}
%
%\thanks{{}$^{(10)}$ Department of Astrophysical Sciences, Princeton University, Princeton, NJ, USA}
%
%\thanks{{}$^{(11)}$ NORC at the University of Chicago and   Illinois Institute of Technology, Chicago, IL, USA; \url{sctchoi@uchicago.edu}}


       
\begin{abstract}      
This technical report records and discusses the Second Workshop on Sustainable Software for
Science: Practice and Experiences (WSSSPE2).  The workshop used an alternative submission
and peer-review process, which led to a set of papers divided across five topic areas:
exploring sustainability;
software development experiences;
credit \& incentives;
reproducibility \& reuse \& sharing; and
code testing \& code review.
The report includes a description of the submission and review process, the workshop
keynote presentations,
a discussion on sustainability, and the five discussions from the topic areas.  The report also
contains a description of potential actions that were proposed in the the five discussions.
\end{abstract}


\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction} \label{sec:intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\katznote{example comment by Dan}
%
%\gabnote{example comment by Gabrielle}
%
%\nchnote{example comment by Neil}
%
%\manishnote{example comment by Manish}
%
%\davidnote{example comment by David}

\note{google doc of notes for reference: \url{http://tinyurl.com/q6ew45v}}
%https://docs.google.com/document/d/1-BxkYWDQ6nNNBXBStUL0xcKF9qCTlEALwf928J_MemI/edit?usp=sharing

The Second Workshop on Sustainable Software for Science: Practice and
Experiences
(WSSSPE2)\footnote{\url{http://wssspe.researchcomputing.org.uk/wssspe2/}} was
held on Sunday, 16 November 2014 in conjunction with the International
Conference for High Performance Computing, Networking, Storage and Analysis
(SC14)\footnote{\url{http://sc14.supercomputing.org}}. WSSSPE2 followed the
model of a general initial workshop,
WSSSPE1\footnote{\url{http://wssspe.researchcomputing.org.uk/wssspe1/}}~\cite{WSSSPE1-pre-report,WSSSPE1},
which co-occurred with SC13, and a focused workshop,
WSSSPE1.1\footnote{\url{http://wssspe.researchcomputing.org.uk/wssspe1-1/}},
which was organized in July 2014 jointly with the SciPy 
conference\footnote{\url{https://conference.scipy.org/scipy2014/participate/wssspe/}}.

Progress in scientific research is dependent on the quality and accessibility of
software at all levels. Hence it is critical to address challenges related to
the development, deployment, maintenance, and overall sustainability of reusable
software as well as education around software practices. These challenges can be
technological, policy based, organizational, and educational, and are of
interest to developers (the software community), users (science disciplines),
software-engineering researchers, and researchers studying the conduct of
science (science of team science, science of organizations, science of science
and innovation policy, and social science communities). The WSSSPE1 workshop
engaged the broad scientific community to identify challenges and best practices
in areas of interest to creating sustainable scientific software. WSSSPE2
invited the community to propose and discuss specific mechanisms to move towards
an imagined future practice for software development and usage in science and
engineering. The workshop included multiple mechanisms for participation,
encouraged team building around solutions, and identified risky solutions with
potentially transformative outcomes. It strongly encouraged participation of
early-career scientists, postdoctoral researchers, and graduate students.

This report extends a previous report that discussed the submission,
peer-review, and peer-grouping processes in detail~\cite{WSSSPE2-pre-report}.
It is also based on a collaborative set of notes taken through a google doc
during the workshop~\cite{WSSSPE2-google-notes}. Overall, the report discusses
the organization work done before the workshop (\S\ref{sec:preworkshop}); the
keynotes (\S\ref{sec:keynotes}); a session on defining sustainability
(\S\ref{sec:defining}); five breakout sessions that explored sustainability
(\S\ref{sec:exploring}); software development experiences (\S\ref{sec:devel});
credit \& incentives (\S\ref{sec:credit}); reproducibility, reuse, \& sharing
(\S\ref{sec:reproduce}); code testing \& code review
(\S\ref{sec:code_testing}); and some conclusions (\S\ref{sec:conclusions}). The
report also includes an incomplete list of attendees (Appendix~\ref{sec:attendees}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Submissions, Peer-Review, and Peer-Grouping} \label{sec:preworkshop}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\note{this section is taken from \cite{WSSSPE2-pre-report}. It could be shortened.}

WSSSPE2 began with a call for papers~\cite{WSSSPE2-pre-report}. Based on the goal of encouraging a wide
range of submissions from those involved in software practice, ranging from
initial thoughts and partial studies to mature deployments, but focusing on
papers that are intended to lead to changes, the organizers wanted to make
submission as easy as possible. The call for papers stated:

\begin{quote} We invite short (4-page) \textbf{actionable} papers that will lead
to improvements for sustainable software science. These papers could be a call
to action, or could provide position or experience reports on sustainable
software activities. The papers will be used by the organizing committee to
design sessions that will be highly interactive and targeted towards
facilitating action. Submitted papers should be archived by a third-party
service that provides DOIs. We encourage submitters to license their papers
under a Creative Commons license that encourages sharing and remixing, as we
will combine ideas (with attribution) into the outcomes of the workshop.
\end{quote}

The call included the following areas of interest:
\begin{quote}
\begin{itemize} 
\renewcommand{\labelenumi}{\textbf{\theenumi}.}
\setlength{\rightmargin}{1em}
\item defining software sustainability in the context of science and engineering
software
\begin{itemize}
\item how to evaluate software sustainability
\end{itemize}

\item improving the development process that leads to new software
\begin{itemize}
\item methods to develop sustainable software from the outset
\item effective approaches to reusable software created as a by-product of
research
\item impact of computer science research on the development of scientific
software
\end{itemize}

\item recommendations for the support and maintenance of existing software
\begin{itemize}
\item software engineering best practices
\item governance, business, and sustainability models
\item the role, operation, and
sustainability of community software repositories 
\item reproducibility, transparency needs that may be unique to science
\end{itemize}

\item successful open source software implementations
\begin{itemize}
\item incentives for using and contributing to open source software
\item transitioning users into contributing developers
\end{itemize}

\item building large and engaged user communities
\begin{itemize}
\item developing strong advocates
\item measurement of usage and impact
\end{itemize}

\item encouraging industry's role in sustainability
\begin{itemize}
\item engagement of industry with volunteer communities
\item incentives for industry
\item incentives for community to contribute to industry-driven projects
\end{itemize}

\item recommending policy changes
\begin{itemize}
\item software credit, attribution, incentive, and reward
\item issues related to multiple organizations and multiple countries, such as
intellectual property, licensing, etc.
\item mechanisms and venues for publishing software, and the role of publishers
\end{itemize}

\item improving education and training
\begin{itemize}
\item best practices for providing graduate students and postdoctoral
researchers in domain communities with sufficient training in software
development
\item novel uses of sustainable software in education (K-20)
\item case studies from students on issues around software development in the
undergraduate or graduate curricula
\end{itemize}

\item careers and profession
\begin{itemize}
\item successful examples of career paths for developers
\item institutional changes to support sustainable software such as promotion
and tenure metrics, job categories, etc.
\end{itemize}

\end{itemize}

\end{quote}


31 submissions were received; all but one used  
arXiv\footnote{\url{http://arxiv.org}} or
figshare\footnote{\url{http://figshare.com}} to self-publish their papers.

The review process was fairly standard, where reviewers bid for papers, then an
automated system matched bids to determine assignments, and reviewers then
completed their assigned reviews (with an average of 4.9 reviews per paper, and
4.1 reviews per reviewer). This process was done through
EasyChair\footnote{http://easychair.org/}, which allowed reviewers to provide
scores on relevance and comments to the organizers, who used the information to
decide which papers to associate with the workshop, and provided the comments to
the authors to help them improve their papers.

The organizers decided to list 28 of the papers as significantly contributing to
the workshop, a very high acceptance rate, but one that is reasonable, given the
goal of broad participation and the fact that the reports were already
self-published.

WSSSPE1 was organized into sessions, each of which was aimed at discussing one
or more of the themes from the call for papers, with a few paper authors invited
to summarize the other papers in them as a panel, followed by general
discussion about that theme. The mapping of papers to themes was done by the
organizers.

For WSSSPE2, the organizers wanted to increase the interactivity of the
sessions, and to open the process of creating the sessions to the full program
committee, the paper authors, and others who might attend the workshop. In order
to do this, the organizers decided to use a breakout format for two sessions,
and to use an open process to determine the breakout topics. Specifically, Well
Sorted\footnote{\url{http://www.well-sorted.org}} was used in the following
steps:
\begin{enumerate}
\item Authors were asked to create Well Sorted ``cards'' for the papers. These
cards have a title (50 characters maximum) and a body (255 characters maximum).
\item Authors, program committee members, and members of the WSSSPE mailing list
were asked to sort the cards. Each person drags the cards, one by one, into
groups. A group can have as many cards as the person wants it to have, and it
can have whatever meaning that makes sense to that person.
\item Well Sorted  produces a set of averages of all the sorts, with various
numbers of card clusters.
\end{enumerate}

The organizers then chose a sort that contained five groups and that felt most
meaningful. After that, they decided on themes for the five groups, namely:
\begin{itemize}
\item Exploring Sustainability
\item Software Development Experiences
\item Credit \& Incentives
\item Reproducibility \& Reuse \& Sharing
\item Code Testing \& Code Review.
\end{itemize}

Finally, since some of the papers were not represented by cards in the process,
they were not placed in groups by the peer-grouping system; the authors of
these papers were asked which groups seemed the best for their papers---these
papers were then placed in those groups. Sections~\ref{sec:exploring}-\ref{sec:code_testing}
discuss the breakout groups, including a list of the papers associated with each
group.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Keynotes} \label{sec:keynotes}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\note{Lead: Choi. \href{http://tinyurl.com/q6ew45v}{Google Notes}.
%https://docs.google.com/document/d/1-BxkYWDQ6nNNBXBStUL0xcKF9qCTlEALwf928J_MemI/edit?usp=sharing
\href{http://tinyurl.com/mnenzms}{Abstracts and slides}}

The workshop featured two keynote addresses. In the opening keynote
presentation, Kaitlin Thaney of the Mozilla Science Lab talked about her
organization's work and policy to enable and support sustainable and
reproducible scientific research through the open web. The second keynote
speaker was Neil Chue Hong of Software Sustainability Institute. He shined a
light on how scientific software is prevalently driving advances in many science
and engineering fields. Both keynote speeches spawned further discussion among
workshop participants on the crucial notion \emph{sustainability} in the theme of
our workshop.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Kaitlin Thaney, Designing for Truth, Scale, and Sustainability}
\label{keynote1}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Kaitlin Thaney is the Director of the Mozilla Science Lab (hereafter Mozilla).
Mozilla is a non-profit organization interested in openness, in news, in website
creation, and in Science, all taking advantage of the open web.

Thaney started noting the unfortunate fact that many current systems suffer the
unintended consequence of creating friction that hinders users, despite
designers' original purposes to do good. An example is the National Cancer
Institute's caBIG. A total of \$350 million was spent, including more than \$60
million for management. More than $70$ tools were created, but caBIG is still
seen as a failure\footnote{\url{http://tinyurl.com/maf6dz2}}. Those that had the
least investment were the most used; the most invested software were the least
utilized.

\begin{comment}
(Kaitlin didn't really say why? Were the tools used? Did they immediately
bit-rot? Was their development unsustained?)-should ask question about this. Is
there a caBIG report available? Quotes from Andrea Califano/Joe Gray, looks like
there is: \url{tinyurl.com/qdodbo7}.
%http://www.informationweek.com/architecture/report-blasts-problem-plagued-cancer-research-grid/d/d-id/1097068

What do we mean by open research? In regard to community/technology/practices

Inefficiency cartoon:  \url{http://www.xkcd.com/1445/}. 
\end{comment}

Thaney emphasized that for efficient reproducible open research, we would need
research tools (e.g., software repositories), social capital (e.g., incentives),
and capacity (e.g., training and mentorship). Our systems would need to
communicate with each other. A point was made by a member of the audience that
as systems become less monolithic, it often becomes harder to sustain the links
between them\footnote{See, for example, \url{http://tinyurl.com/l76tba2}.}.
%http://www.slideshare.net/jameshowison/scientific-software-sustainability-and-ecosystem-complexity
%(but does Anon Grizzly have other cites/info for that?).
%In contrast, works licensed by Creative Commons typically do not 
%have dependencies (a book, a photo, an artwork).

Thaney spoke about Mozilla's work around code citation, through a collaboration
and prototype crafted between Mozilla, Github, figshare and Zenodo. This work
was presented at a closed meeting in May 2014 at the National Institutes of
Health (NIH) around these issues, sparking a conversation from that meeting
around what a \emph{Software Discovery
Index}\footnote{\url{http://softwarediscoveryindex.org/report/}} might look
like. The meeting included a number of publishers, researchers, and those behind
major scientific software efforts such as Bioconductor, Galaxy, and
nanoHUB. 
%facilitates more efficient scientific research. SDI identifies scientific
%software by archiving and standardizing metadata for software and hence help
%connect both developers and users.
Ted Habermann in the audience commented that if the metadata is minimal, it
would be less onerous for data providers, but more burdensome for users---it
could be challenging to keep a balance between what have to be captured and what
would be ideal if we do not want to lose user engagement as in the case of the
old Harvard Dataverse, finding often only the first four fields of three pages
of metadata were filled out.
 
The speaker concluded her talk urging the audience to design scientific software
with the general community, not an individual, in mind; and to design to unlock
latent potential of our systems. In addition, she encouraged everyone to rethink
how we reward researchers and support roles.
%Lastly, she cautioned the community to be mindful of jargon or semantics traps.


%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Neil Chue Hong, We are the 92$\%$} 
\label{keynote2}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{comment}
In a recent survey of UK research-intensive universities, 92\% of researchers
said they used research software and 68\% said their research would be impossible
without software. Yet 71\% have had no formal software training, and few are
ready to apply many of the things we take for granted such as testing or
virtualization. WSSSPE represents the pinnacle of what we understand to be the
best practice around scientific software in our community. My talk will
challenge the workshop participants to come up with ways of taking this best
practice to those 92\% of researchers in a way that will lead to maximum benefit
to the scientific community.
 \end{comment}

%\url{http://dx.doi.org/10.6084/m9.ﬁgshare.1243288} 

Neil Chue Hong is currently serving as the Director of the Software
Sustainability Institute (SSI), United Kingdom. Chue Hong started with making the
point that world-leading research relies on software, quoting Kersten Kleese Van
Dam of the Pacific Northwestern National Laboratory via the campaign
\href{http://change.org}{change.org}, ``\emph{Today there are very few science
areas left which do not rely on IT and thus software for the majority of the
their research work. More importantly key scientific advances in experimental
and observational science would have been impossible without better software.}''
He also cited Daniel Katz, Software Infrastructure for Sustained Innovation (SI2) Program Director of the
National Science Foundation, ``\emph{Scientific discovery and innovation are
advancing along fundamentally new pathways opened by development of increasingly
sophisticated software. Software is an integral enabler of computation,
experiment and theory, and directly responsible for increased scientific
productivity and enhancement of researchers' capabilities.}''

Chue Hong drew attention to the fact that we too often disregard hundreds of
thousands of software researchers thinking they are the long tail. We forget
that actually they are the mainstream and we are the elite minority. He
emphasized that software is no longer special; it is both essential to and common in scientific
research. A survey of researchers from 15 Russell Group universities conducted by
the SSI between Aug--Oct 2014, which included a total of 406 respondents covering a
representative range of funders, disciplines, and seniority, reported that 92\% confirmed the
use of research software such as MATLAB, SPSS, Excel, etc. and 89\%
affirmed that it would be impossible or difficult to conduct research without
software. Nevertheless the British research community is just starting to
understand the magnitude of the issue. In the aforementioned SSI survey, 56\% of
researchers developed their own research software, 71\% had no formal
software-development training, 140,000 researchers relied on their own coding
skills, and only 4\% of jobs advertised in British universities were software related.
 
According to Chue Hong, costs of software-reliant research in the United Kingdom
included \textsterling 840 million of investment in the financial year
2013--2014, and this amount has risen by 3\% on average over the past four years.
About 30\% of total research investment has been spent on research that relies
on software over the last four financial years. These numbers stemmed from an
analysis of data from $49,650$ grant titles and abstracts published on Gateway
to Research between years 2010 and 2014.
 
Chue Hong led the audience in discussing the following questions: What are we going to
\emph{do} to help and benefit software researchers and to achieve software
sustainability if~92\% of researchers and WSSSPE care about scientific software?
Who do we need to persuade? What are the incentives we need to put in place? He
challenged the workshop participants to change the current deficient practices
in research and academia.

\begin{comment}
With apologies to Greg Wilson:
\href{http://software-carpentry.org/blog/2013/10/you-keep-using-that-word.html}
{You Keep Using That Word}
We can talk all day about the best ways of achieving sustainability
But what are we going to do to make it actually sustainable?

Careers outside academic sector: 
Non-university Research (industry, government, etc.)
UK STEM graduate career paths: Early Career Research, Permanent Research Staff,
Professor.
The Scientific Century, Royal Society, 2010 (revised to reflect first stage
clarification from ``What Do PhD's Do?'' study.)
Who	are the people  we need to persuade?
What	 are	the incentives we need to put in place?
How are we going to show that the work we present here has benefit to the 92\%?
We are all the 92\%	and we can change the world if we	want!
\end{comment} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Defining Sustainability} \label{sec:defining}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo{writing led by Dan - other contributions welcome}

In the first interactive session, the attendees divided themselves into groups
to discuss software sustainability. They were asked to
\begin{enumerate}
\item discuss what the term ``software sustainability'' meant to them

\item determine three things they considered to be significant enablers of
software sustainability

\item determine three things they considered to be significant barriers to
software sustainability
\end{enumerate}
Once each group had come up with answers, all the answers were compiled, and the
attendees voted on which they thought were important by a show of hands.

The general responses to what software sustainability meant were:
\begin{itemize}
\item keeping software scientifically useful
\item separating techniques in code from knowledge in code
\item that an adequately large community finds value in software and is willing
to sustain it
\end{itemize}

\katznote{any discussion of this?}

The enablers of and barriers to software sustainability, roughly ranked by
attendee votes are shown in
{\tablename}s~\ref{tb:software_sustainability_enablers} and
\ref{tb:software_sustainability_barriers}, respectively.\footnote{A few other
items were suggested as barriers, but were not voted on due to lack of time in
the session:
layering up dependencies;
using software past its sustainable life;
using software past its usable life;
inertia for accepted answers vs wrong/right answers;
monolithic or poor code; and
need to restructure code when hardware/software/libraries change.
}

\katznote{any discussion of these tables?}

\begin{table*}[th]
\begin{center}
\caption{Enablers of software sustainability, with 0 to 10 `*'s roughly
indicating the fraction of attendees who voted for an item as important.}
    \begin{scriptsize}
    \begin{tabular}{ | p{1.65cm} | p{10.0cm} |}
    \hline
  Importance & item \\ \hline \hline
********** & healthy and vibrant communities; vibrant community to champion software \\ \hline
********** & designing for growth and extension --- open development \\ \hline
******* & culture in community for reuse \\ \hline
**** & portability \\ \hline
**** & culture in dev community to support transition between developers \\ \hline
*** & interdisciplinary people : science + IT experience \\ \hline
** & planning for end of life \\ \hline
** & make smart choices about dependencies \\ \hline
* & thinking of software as product lines --- long term vs.~short term view \\ \hline
 & not all communities need new software \\ \hline
 & converting use into resources \\ \hline
    \end{tabular}
    \end{scriptsize}
    \label{tb:software_sustainability_enablers}
\end{center}   
\end{table*} 

\begin{table*}[ht]
\begin{center}
\caption{Barriers to software sustainability, with 0 to 10 `*'s roughly
indicating the fraction of attendees who voted for an item as important.}
    \begin{scriptsize}
    \begin{tabular}{ | p{1.65cm} | p{10.0cm} |}
    \hline
  Importance & item \\ \hline \hline
******* & lack of incentives, including promotion and tenure process; promotion
and tenure process in academic is incompatible with sustainability \\ \hline
*****  & absent or poor documentation \\ \hline
***** & funding to ensure sustainability is difficult to obtain \\ \hline
**** & developers are not computer scientists; don't have software engineering
practices (in particular, those needed to scale-up projects to support and be
developed by a large sustainable community) \\ \hline
*** & overreliance on one or two people - bus test \choinote{What does ``bus test'' mean?}\\ \hline
** & rate of change of underlying technologies \\ \hline
** & lack of business models for sustainability \\ \hline
* & lack of training for how to build sustainability into the system \\ \hline
 & maintenance needed for software is not visible, appears to ``just happen'' \\ \hline
 & licensing issues \\ \hline
 & staff turnover - lack of continuity \\ \hline
    \end{tabular}
    \end{scriptsize}
    \label{tb:software_sustainability_barriers}
\end{center}   
\end{table*} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exploring Sustainability} \label{sec:exploring}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\todo{Colin to lead writing of this section.}

\note{\href{http://tinyurl.com/mpbhvyb}{Google doc notes}}
%https://docs.google.com/a/uchicago.edu/document/d/10XkshP3YjXnA5JQgP-UFHbOxshWczzehWGSo6V7bNH4/edit

\todo{short intro to group here}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Discussion and Actions}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Papers}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The papers that were discussed in the Exploring Sustainability group are:
\begin{itemize}
\item Mario {Rosado de Souza} and Robert Haines and Caroline Jay. Defining
Sustainability through Developers' Eyes: Recommendations from an Interview
Study~\cite{wssspe2_rosada_de_souza}

\item Robert Downs, W. Christopher Lenhardt, Erin Robinson, Ethan Davis,
Nicholas Weber. Community Recommendations for Sustainable Scientific
Software~\cite{wssspe2_downs}

\item Abani Patra, Matthew Jones, Steven Gallo, Kyle Marcus and Tevfik Kosar.
Role of Online Platforms, Communications and Workflows in Developing Sustainable
Software for Science Communities~\cite{wssspe2_patra}

\item Marlon Pierce, Suresh Marru and Chris Mattmann.{WSSSPE2}: Patching It Up,
Pulling It Forward~\cite{wssspe2_pierce}

\item Justin Shi. Seeking the Principles of Sustainable Software
Engineering~\cite{wssspe2_shi}

\item Colin C. Venters, Michael K. Griffiths, Violeta Holmes, Rupert R. Ward and
David J. Cooke. The Nebuchadnezzar Effect: Dreaming of Sustainable Software
through Sustainable Software Architectures~\cite{wssspe2_venters}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Software Development Experiences} \label{sec:devel}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\todo{Nancy to lead writing of this section}

\note{\href{http://tinyurl.com/pn4eq8z}{Google doc notes}}
%https://docs.google.com/a/uchicago.edu/document/d/1_q0jmiEPNFRGAEtGLk_QxQ1vVokgTDYruTGURowNGkY/edit

\todo{short intro to group here}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Discussion and Actions}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Papers}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The papers that were discussed in the Software Development Experiences group are:
\begin{itemize}
\item Jordan Adams, Sai Nudurupati, Nicole Gasparini, Daniel Hobley, Eric
Hutton, Gregory Tucker and Erkan Istanbulluoglu. Landlab: Sustainable Software
Development in Practice ~\cite{wssspe2_adams}

\item Alice Allen and Judy Schmidt. Looking before leaping: Creating a software
registry~\cite{wssspe2_allen}

\item Carl Boettiger, Ted Hart, Scott Chamberlain and Karthik Ram. Building
software, building community: lessons from the {ROpenSci}
project~\cite{wssspe2_boettiger}

\item Michael R. Crusoe and C.Titus Brown. Channeling community contributions to
scientific software: a hackathon experience~\cite{wssspe2_crusoe}

\item Yolanda Gil, Eunyoung Moon and James Howison. No Science Software is an
Island: Collaborative Software Development Needs in
Geosciences~\cite{wssspe2_gil}

\item Ted Habermann, Andrew Collette, Steve Vincena, Werner Benger, Jay Jay
Billings, Matt Gerring, Konrad Hinsen, Pierre de Buyl, Mark K\"{o}nnecke, Filipe
Rnc Maia and Suren Byna. The Hierarchical Data Format ({HDF}): A Foundation for
Sustainable Data and Software~\cite{wssspe2_habermann}

\item Marcus Hanwell, Patrick O'Leary and Bob O'Bara. Sustainable Software
Ecosystems: Software Engineers, Domain Scientists, and Engineers Collaborating
for Science~\cite{wssspe2_hanwell}

\item Eric Hutton, Mark Piper, Irina Overeem, Albert Kettner and James Syvitski.
Building Sustainable Software - The {CSDMS} Approach~\cite{wssspe2_hutton}

\item W. Christopher Lenhardt, Stanley Ahalt, Matt Jones, J. Aukema, S. Hampton,
S. R. Hespanh, R. Idaszak and M. Schildhauer. {ISEES-WSSI} Lessons for
Sustainable Science Software from an Early Career Training Institute on Open
Science Synthesis~\cite{wssspe2_lenhardt}

\item Jory Schossau and Greg Wilson. Which Sustainable Software Practices Do
Scientists Find Most Useful?~\cite{wssspe2_schossau}

\item James S. Spencer, Nicholas S. Blunt, William A. Vigor, Fionn D. Malone, W.
M. C. Foulkes, James J. Shepherd and Alex J. W. Thom. The {H}ighly {A}ccurate
{N-DE}terminant ({HANDE}) quantum {Monte Carlo} project: Open-source stochastic
diagonalisation for quantum chemistry~\cite{wssspe2_spencer}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Credit \& Incentives} \label{sec:credit}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\todo{Dan leading writing of this section}

\note{\href{http://tinyurl.com/k8ruyn9}{Google doc notes}}
%https://docs.google.com/document/d/1Jsi_trBT5cjEXVnGjGHJpcIhMEcVpAn6XmYNxfIHXv0/edit#heading=h.gk1dzxu9wi6q

This group, with just three papers but a large amount of interest and
participation from attendees, focused on the institutional, social, and cultural
mechanisms that encourage the creation and maintenance of shared software, in the
context of what now exists but focusing on what mechanisms are desired and how
we might achieve them.


%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Discussion and Actions}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In the first discussion session, this group decided to break into two smaller groups,
each independently working through the same general topic: credit and incentives.

\subsubsection{First breakout discussion: Group A}
The first sub-group discussed issues around the current system for credit and current
incentives, which it called ``hacking the incentive structure.'' The group
considered four potential points of leverage:

First, that we currently have systems that collect information, and these could
be modified to collect different information, then map that information to
actions. We could initially build a proof-of-concept for a new use of a given
system, then determine what actions would be needed to make this use more
common.

Second that we could create entirely new systems, perhaps because the existing
systems are too tied to what they measure, and modifying them is not practical.

Third that we could change academic culture, rather than worrying about the
systems. This was mostly focused on citations, because they matter for hiring,
promotion, and tenure decisions. The group discussed how we could weigh the
citations within papers better than we now do? How could we identify the five
citations that really matter for a paper, distinguishing them from the related
works and general background that are also cited. Perhaps we could break these
out in the reference list, working with publishers to implement this. Or maybe
we could also break out categories of citations, such as the most important
software used, the previous publication that we are building from, the data that
we actually used, etc. The Moore Foundation's award in data science \choinote{cite} was given as
an example, asking proposers: What are the five canonical citations that are
most important to your work? This would be a way of giving credit and assigning
importance to these works, differently from how we just count citations today. A
possible action that the group discussed was conducting a longitudinal study of
most useful \{software, data, etc.\} in a discipline.

Fourth, that we could change the ways funders make decisions, and use these funding
policies as incentives.

After this discussion, group A brainstormed about incentives,
with the following items suggested:
\begin{itemize}
\item running programming contests, creating bounties for contributing to open
source software, etc.
\item augment author lists to give credit to people who don't now get credit
(and making them machine readable)
\item developing a microcitation standard and mechanism (for both software and
data)
\item developing a well-defined standard for author contribution -- what level
of contribution rises to the level of authorship?
\item leveraging social media for citation and reviewing of content -- then
using social media to bring more people into the review process than is
traditional
\item determining where else software can be cited and recorded (e.g.,
acknowledgments sections of papers)
\item developing a taxonomy of contributors, tied to places that these metrics
are already stored (e.g., ORCID) \choinote{cite}
\item making metadata easier to add for software, creating incentive for
providing software metadata -- note that this cannot be centralized
\item creating something like the h-index that tenure committees can make use of
- simplify a way of measuring and documenting the overall credit given to an
individual over different projects
\item thinking about publishing software versus journal - software does not have to
be novel
\item determining guidelines for recommending software characteristics for
tenure - perhaps draft guidelines then get ACM or IEEE agreement
\end{itemize}


\subsubsection{First breakout discussion: Group B}

This group started by discussing who should be incentivized, thinking of two
categories of people: those in science (who could be incentivized to do better,
more shareable, more sustainable work), and those in industry but interested in
science (who could be incentivized to contribute to science.) It was pointed out
that we are not yet clear enough on exactly what we want to incentivize,
suggesting that we need to have a clearer picture of ``good computational work"
and what sort of contributions are truly generative for science.

The discussion of incentivizing those in science acknowledged that the
publications system was far from perfect for incentivizing good software work.
Nonetheless discussion focused on bringing software people into publications.
There were two main suggestions. The first is to focus on end users of software
and encourage them to cite software the ``right" way. James Howison suggested
that his research showed that few projects were making a formal request for
citation (but that authors weren't necessarily following those suggestions
anyway) \cite{howison2015jasist}. He suggested making access to the software
conditional on a license that requires citation. Others found this ``too
confrontational" and preferred to concentrate on making it easier to do the
right thing. The second was focusing on those leading software projects, and the
group was more enthusiastic about ``forcing" PIs to include their ``software
people" on publications, although there were few ideas on how exactly to do
this. Another technique mentioned was that when scientific software projects are
hosted in organizations like Apache, the scientific contributors can benefit
from building their reputations, perhaps yielding job offers that they can use
to negotiate better job and career packages.

The discussion on incentivizing those outside science focused on accessing the
well of affection that those working in software have for scientific research.
How can the interest and skills of this group be marshaled towards sustainable
contributions? There is evidence that the migration of scientific software
projects to the Apache Foundation has created opportunities for those not
employed in the scientific center to contribute to projects initiated by
scientists (especially where there is cross-over with industry needs, such as
provenance and workflow).

The group also discussed developing ``software prizes" arguing that while it is
hard to ``mint" other new sources of reputation, prizes are possible without
getting too many others on board. The prize criteria can form a template for
describing what we mean by scientific contributions made through software,
particularly focusing on building active communities, not only writing great
code.

\subsubsection{Group merger and redivision}

After the first breakout session, the groups A and B came together and discussed
a rollup of the ideas from the subgroups at a high level:
\begin{itemize}
\item citation ecosystem - traces of usage (metrics)
\item taxonomy of contributorship, understanding roles
\item prizes
\item new metrics (for people's activities in software)
\item guidelines for evaluating scientific contribution through software (perhaps 
using new metrics)
\end{itemize}

In the remaining discussion sessions, the group chose to split into three
subgroups to discuss a version of these topics: {\em citation ecosystems}, {\em
taxonomy of contributorship/guidelines for software for tenure review}, and {\em
prizes}. The subgroups were asked to clearly identify
\begin{itemize}
\item the problem to be solved
\item steps towards a solution.
\end{itemize}



\subsubsection{Remaining breakout discussions: Citation ecosystems}

\note{for reference, notes are in \url{http://tinyurl.com/l4tc6a4}}
%https://docs.google.com/document/d/1SOja7k0mXwvOB2tQD3ZW3O38Qv4NwfA21zdMQ9JlUQc/edit

This group defined its goal as creating a low-barrier-of-entry method for
recording names and roles (and in a second phase, optionally including weights)
of contributors (coders and other intellectual contributions) to a software
package in a machine readable way (to be called a credit file), then encouraging
the scientific community to adopt this practice.

The following general points were initially discussed: 
\begin{itemize}
\item The FLASH \choinote{cite} project was suggested as an example of how something 
like this has been done.
\item This data could be a file that can be associated with a citation to the 
software, either through use of a DOI for the credit file, or by uploading the 
credit files as associated with the paper.
\item This idea could also be applied to data
\item This data (the credit file) should be part of the metadata that is outside
of paywalls, like citations are now.
\item It was suggested that there should also be a separate file to track
software dependencies, but this is not the same file. 
\end{itemize}

The group came up with the following actions to be performed:
\begin{enumerate}
\item Build a tool that can automatically determine who the contributors are 
(from a git or other repo), then allows the user to manually edit the output to 
add/remove people, define roles. 
\item Work with repositories to encourage them to provide the information we 
need based on what they already store.
\item Define what a citation file should look like and what it should be called.
\item Test adoption, for example, with LBNL.
\item Create credit file for a set of software.
\item Build a validator (and perhaps a visualizer) for credit files.
\item Write a tool to collect files and visualize/output interconnections (which 
software is used with which), based on an existing project.
\item When we (the group members) write papers, we should track the software 
we use, and encourage the software developers to make their software citable 
and create credit files.
\item Build a tool to export the credit file to BibTex and other citation styles.
\item Make sure the BibTex entries (exported from internal data) are somewhat 
standardized so that they can be imported into papers.  Also make sure that 
standard LaTeX style files understand and accept these entries.
\end{enumerate}




\subsubsection{Remaining breakout discussions: Taxonomy of contributorship/guidelines for software for tenure review}
\note{by Frank Seinstra}

\note{for reference, notes are in \url{http://tinyurl.com/mx58tmx}}
%https://docs.google.com/document/d/1sDZLaBR2elZ9Tj6eLIwEtf5VqQ_x_AN_SetKtJlFUpI/edit

At the start of the discussion, the breakout group brought forth the important
observation of the wide disparity in commonly accepted habits of publication in
different research fields. In domains which have, historically, relied on large
groups of researchers collaborating towards a common goal (e.g., high-energy
physics, astronomy), publications often have tens or even hundreds of co-authors
(with some papers in experimental particle physics having over 3000.) In other
domains, the number of co-authors is typically much smaller, with, in some
cases, even a preference for single-author papers. Similarly, the various
platforms for publication are valued differently in different domains. Most
commonly, publications in peer-reviewed scientific journals are regarded as the
most important and most impactful. However, in certain domains, especially in
Computer Science, many researchers typically regard conference proceedings as
their prime publication target. It is often suggested that this difference is
due to the rapid developments in ICT science, a pace that can not be upheld by
traditional peer-reviewed journals. Whatever the causes, any useful taxonomy of
contributorship or guideline for tenure review should take such differences into
account.

Despite these differences, and despite the fact that software often has taken
the role of a proper, albeit less tangible, scientific research instrument,
neither the software nor its creators are commonly credited as part of a
scientific publication. The group acknowledged the need for more recognition for
the creators of such software instruments, and indicated a number of possible
pathways. First and foremost, domain scientists must be made aware of the
important role of software, and include the developers as co-authors of papers.
A second approach is to fully embrace an open badging infrastructure (such as
Mozilla's Open Badges), where a {\em badge\/} is a free, transferrable,
evidence-based indicator of an accomplishment, skill, quality, or interest. A
third approach is for the scientific community to support the increasing
momentum of peer-reviewed journals specialized in the open source/open access
publication of scientific research software, such as Computer Physics
Communication, F1000 Research, Journal of Open Research Software, and SoftwareX.

Recognizing publication of research software as a proper scientific contribution
raises several important but currently unsolved questions, however. For example,
is the number of users of the software a relevant measure of impact? What
standards of coding quality must be followed in order to justify publication and
hence recognition? Should the release of a new version of the software be
eligible for a new publication; if so, under what conditions? And above all:
should software publications be valued in the same way as traditional scientific
publications? Or is there a need for new measures of productivity and impact?

In part, the answers will come from the scientific community at large, as a
natural consequence of growing awareness and mindset change. Some of the
answers, however, also should be based on decades of experience in (and
developing standards for) implementing, maintaining, refactoring, documenting,
testing, and deploying software instruments in scientific research. Care should
be taken, however, not to impose such standards for all domains in equal ways
right from the start. Forerunners should serve as an example, but should not
scare away domains that have based their progress on much less advanced methods
of {\em software carpentry}. Nevertheless, proper guidelines are needed, which
eventually should be followed across all domains. The group also recognized that
funding bodies, universities, and publishers eventually should demand that
research projects follow such guidelines, and to implement a proper software
sustainability plan.

To enable a form of standardized crediting for developers of research software,
the group proposed to work towards a taxonomy for software-based
contributorship. The taxonomy should be derived from, or extend, existing
taxonomies for research impact and contributorship such as defined by CASRAI (in
particular based on the Wellcome-Harvard contributorship taxonomy\katznote{Dan
to add cite or url}), VIVO, or ISNI. An interesting measure of impact raised by
the group was the {\em betweenness centrality}, an indicator of a person's
centrality (and hence, importance) in a scientific collaboration. It is expected
that developers of research software often play such a central role.

The group defined the following actions to be performed:
\begin{enumerate}
\item Investigate existing taxonomies for roles and contributorships.
\item Investigate prototype badging initiatives.
\item Investigate journals focusing on publishing peer-reviewed research
software.
\item Investigate guidelines and checklists of best practices.
\item Communicate the results of the above investigations to the WSSSPE
community, and to decision-making bodies (funders, publishers, universities,
and tenure committee representatives).
\item Ensure engagement of the broader research community in this discussion.
\end{enumerate}



\subsubsection{Remaining breakout discussions: Prizes}\label{sec:prizes}
\note{sub-breakout notes: \url{http://tinyurl.com/mjok4o5}}
%https://docs.google.com/document/d/1foSppeHQeQ-qOjd-Rp_CUCNy8JMLxd_vrCDMmqvG2-w/edit 

This group discussed the idea of prizes.  Prizes are expected to reframe software
as ``instrument building'' but will prizes be good or bad, and how can we make sure
there are no negative affects and the process cannot be gamed?
  
Prizes in different categories were discussed (like Academy Awards), for example:
best contribution (non-founder),
broadest diversity of contributions,
best tutorials or documentation,
best leadership transition (award ex leader and new leader),
best generalization (taking something that was limited and making it more general), and
best mentorship of contributors (bringing others into the community).
 
\katznote{I don't understand this at all.  Can someone explain it?}
There are also other indirect forms of incentives
(though these are not a direct prize, they still can incentivize someone):
\begin{itemize}
\item Converting reputation by joining the Apache Software Foundation, Google, etc. 
\item Inviting ASF and open source people to contribute to scientific code (at
least on questions of overlapping
\item Template for assessing scientific contributions made through software.   
\end{itemize}

To determine who should give prizes, perhaps we should find those who we think would
be awarded prizes, then ask them who they would want to receive a prize from, then
ask those organizations to see if they are willing to be involved in the process.

One idea is to create a funding program for disciplines or other organizations to
create a prize program.  We provide a framework, for example: awards to individuals, must
award in 5 or 6 areas, must have a jury and/or objective criteria that includes
senior/junior domain people and technology people, must have the recipients awarded
at a relevant event, must provide citations that explain why the prizes should be awarded.
A concern is that having many organizations award prizes may reduce the impact.

Possible awarders are AAAS, Nature Publishing Group, ACM/IEEE, Astro, Ecology
Society of America, etc. Or perhaps this should be a joint technology/science
partnership, for example, the [Apache $|$ Mozilla]--[AAAS $|$ disciplinary
society] prize?

Some potential criteria for prizes are:
community engagement, helping out others;
number of unique contributors;
adding new pieces of functionality to software;
integrating software into broader ecosystem; championing broad principles of
sustainability, open science, open source, etc.;
improving accessibility to software, to scientific software (perhaps championing
inclusiveness or making software accessible?);
documentation;
tutorials;
commits / patching;
leadership transition; and
best contribution by a non-founder.

Perhaps there should be different criteria for ``established'' members of the
community versus junior members? Or perhaps prizes should be restricted to
junior members?

An important point is that we don't want to give prizes just to reward people
who are really good at this one thing, but rather we want to reward people who
are building the culture we want as scientists.

 



%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Papers}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The papers that were discussed in the Citation \& Incentives group are:
\begin{itemize}
\item James Howison. Retract bit-rotten publications: Aligning incentives for
sustaining scientific software~\cite{wssspe2_howison}

\item Daniel S. Katz and Arfon M. Smith. Implementing Transitive Credit with
{JSON-LD}~\cite{wssspe2_katz}

\item Ian Kelley. Publish or perish: the credit deficit to making software and
generating data~\cite{wssspe2_kelley}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Reproducibility \& Reuse \& Sharing} \label{sec:reproduce}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\todo{Neil OR VOLUNTEER to lead writing of this section}

\note{\href{http://tinyurl.com/kqpe87z}{Google doc notes}}
%https://docs.google.com/document/d/1Mivadj16_9tPrw8Nxmhp72AtNC0BEVO-f7M84FXTbSU/edit#heading=h.elaktnt2tep9

\todo{short intro to group here}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Discussion and Actions}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Papers}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The papers that were discussed in the Reproducibility \& Reuse \& Sharing group are:
\begin{itemize}
\item Jakob Blomer, Dario Berzano, Predrag Buncic, Ioannis Charalampidis,
Gerardo Ganis, George Lestaris and Ren\'{e} Meusel. The Need for a Versioned
Data Analysis Software Environment~\cite{wssspe2_blomer}

\item Ryan Chamberlain and Jennifer Schommer. Using {Docker} to Support
Reproducible Research~\cite{wssspe2_chamberlain}

\item Neil Chue Hong. Minimal information for reusable scientific
software~\cite{wssspe2_chue_hong}

\item Tom Crick, Benjamin A. Hall and Samin Ishtiaq. ``Can I Implement Your
Algorithm?'': A Model for Reproducible Research Software~\cite{wssspe2_crick}

\item Bryan Marker, Don Batory, Field G. Van Zee and Robert van de Geijn. Making
Scientific Computing Libraries Forward Compatible~\cite{wssspe2_marker}

\item Stephen Piccolo. Building Portable Analytical Environments to improve
sustainability of computational-analysis pipelines in the
sciences~\cite{wssspe2_piccolo}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Code Testing \& Code Review} \label{sec:code_testing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\todo{Karen to lead writing of this section}

\note{\href{http://tinyurl.com/l5t5h45}{Google doc notes}}
%https://docs.google.com/document/d/1G1_U5-hkAvDKtTgT4DvUhIYvyYUY4cBBvQHJIdgADa0/edit#heading=h.v7g0nqpn1fur

\todo{short intro to group here}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Discussion and Actions}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\subsection{Papers}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The papers that were discussed in the Code Testing \& Code Review group are:
\begin{itemize}
\item Thomas Clune, Michael Rilee and Damian Rouson. Testing as an Essential
Process for Developing and Maintaining Scientific Software~\cite{wssspe2_clune}

\item Marian Petre and Greg Wilson. Code Review For and By
Scientists~\cite{wssspe2_petre}

\item Andrew E. Slaughter, Derek R. Gaston, John Peterson, Cody J. Permann,
David Andrs and Jason M. Miller. Continuous Integration for Concurrent {MOOSE}
Framework and Application Development on {GitHub}~\cite{wssspe2_slaughter}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions} \label{sec:conclusions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\todo{currently just pre-workshop stuff - needs to be updated}

The WSSSPE2 workshop continues our experiment from WSSSPE1 in how we can
collaboratively build a workshop agenda. The differences in WSSSPE2 from WSSSPE1
are in using an existing service (EasyChair) to handle submissions and reviews,
rather than an ad hoc process, and using an existing service (well-sorted) to
allow collaborative grouping of papers into themes by all authors, reviewers,
and the community, rather than this being done in an ad hoc manner by the
organizers alone. \choinote{Are lightning talks a new feature in WSSSPE2?}

The fact remains that contributors also want to get credit for their
participation in the process. And the workshop organizers still want to make
sure that the workshop content and their efforts are recorded. Ideally, there
would be a service that would be able to index the contributions to the
workshop, serving the authors, the organizers, and the larger community. But
since there still isn't such a service today, the workshop organizers are
writing this initial report and making use of arXiv as a partial solution to
provide a record of the workshop.

After the workshop, one or more additional papers will be created that will
include the discussions at the workshop. These papers will likely have many
authors, and may be submitted to peer-reviewed journals.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments} \label{sec:acks}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\todo{feel free to add stuff here}

Work by Katz was supported by the National
Science Foundation while working at the Foundation.  Any opinion, finding, and
conclusions or recommendations expressed in this material are those of the
author(s) and do not necessarily reflect the views of the National Science
Foundation.


\appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Attendees}  \label{sec:attendees}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The following is a partial list of workshop attendees who registered on the
collaborative notes document~\cite{WSSSPE2-google-notes} that was used
for shared note-taking at the meeting, or who participated in a breakout groups
and were noted in that group's notes.

{\small
\begin{longtable}{ll}
   Jordan Adams          &  Tulane University
\\ Alice Allen           &  Astrophysics Source Code Library (ASCL)
\\ Gabrielle Allen       &  U Illinois
\\ Pierre-Yves Aquilanti &  TOTAL E\&P R\&T USA
\\ Wolfgang Bangerth & Texas A\&M
\\ David Bernholdt       &  Oak Ridge National Laboratory
\\ Jakob Blomer
\\ Carl Boettiger        &  UCSC/ropensci
\\ Chris Bogart          &  ISR/CMU
\\ Steven R.~Brandt      &  Louisiana State University
\\ Tom Clune             &  NASA GSFC
\\ John W.~Cobb
\\ Dirk Colbry           &  Michigan State University
\\ Karen Cranston        &  NESCent
\\ Tom Crick             &  Cardiff Metropolitan University, UK
\\ Ethan Davis           &  UCAR Unidata
\\ Robert R Downs        &  CIESIN, Columbia University
\\ Anshu Dubey           &  Lawrence Berkeley National Laboratory
\\ Nicole Gasparini      &  Tulane University, New Orleans
\\ Yolanda Gil           &  Information Sciences Institute, University of Southern California
\\ Kurt Glaesemann       &  Pacific northwest national lab
\\ Sol Greenspan         &  National Science Foundation
\\ Ted Habermann         &  The HDF Group
\\ Marcus D.~Hanwell     &  Kitware
\\ Sarah Harris          &  University of Leeds
\\ David Henty           &  EPCC, The University of Edinburgh
\\ Neil Chue Hong        &  Software Sustainability Institute \& University of Edinburgh
\\ James Howison         &  University of Texas
\\ Maxime Hughes
\\ Eric Hutton           &  University of Colorado
\\ Ray Idaszak           &  RENCI/UNC
\\ Samin Ishtiaq         &  Microsoft Research Cambridge, UK
\\ Matt Jones            &  University of California Santa Barbara
\\ Nick Jones            &  New Zealand eScience Infrastructure, University of Auckland
\\ Daniel S.~Katz        &  U Chicago \& Argonne
\\ Ian Kelley
\\ Hilmar Lapp           &  National Evolutionary Synthesis Center (NESCent) and Duke University
\\ Chris Lenhardt
\\ Richard Littauer      &  MIT/University of Saarland
\\ Frank L\"{o}ffler     &  Louisiana State University
\\ Andre Luckow          &  Rutgers
\\ Berkin Malkoc         &  Istanbul Technical University
\\ Kyle Marcus           &  University at Buffalo
\\ Bryan Marker          &  The University of Texas at Austin
\\ Suresh Marru          &  Indiana University
\\ Robert H.~McDonald    &  Indiana University - Data to Insight Center/Libraries
\\ Rupert Nash
\\ Andy Nutter-Upham     &  Whitehead Institute
\\ Abani Patra           &  University at Buffalo
\\ Aleksandra Pawlik     &  Software Sustainability Institute
\\ Cody J.~Permann       &  Idaho National Laboratory
\\ John W.~Peterson      &  Idaho National Laboratory
\\ Benjamin Pharr        &  University of Mississippi
\\ Stephen Piccolo       &  Brigham Young University, Utah
\\ Marlon Pierce         &  Indiana University
\\ Ray Plante            &  NCSA/University of Illinois Urbana-Champaign
\\ Sushil Prasad         &  Georgia State University, Atlanta
\\ Karthik Ram           &  University of California, Berkeley. Berkeley Institute for Data Science and rOpenSci
\\ Mike Rilee            &  NASA/GSFC, Rilee Systems Technologies
\\ Erin Robinson         &  Foundation for Earth Science
\\ Mark Schildhauer      &  NCEAS, Univ. California, Santa Barbara
\\ Jory Schossau         &  Michigan State University
\\ Frank Seinstra        &  Netherlands eScience Center
\\ James Shepherd        &  Rice University
\\ Justin Shi
\\ Ardita Shkurti        &  University of Nottingham
\\ Alan Simpson          &  EPCC, The University of Edinburgh
\\ Carol Song            &  Purdue University
\\ James Spencer         &  Imperial College London
\\ Tracy Teal            &  Data Carpentry
\\ Kaitlin Thaney        &  Mozilla Science Lab
\\ Matt Turk             &  NCSA/UIUC
\\ Colin C.~Venters      &  University of Huddersfield
\\ Nathan Weeks
\\ Ethan White           &  University of Florida/Utah State University
\\ Nancy Wilkins-Diehr   &  SDSC
\\ Greg Wilson           &  Software Carpentry
\end{longtable}
}

\bibliographystyle{plain}

\bibliography{wssspe}
\end{document}

