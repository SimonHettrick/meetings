%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metrics Working Group Discussion}
\label{sec:appendix_metrics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Gabrielle Allen \footnote{email: \href{mailto:gdallen@illinois.edu}{gdallen@illinois.edu}} will serve as the point of contact for this working group.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Group Members}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{itemize}
\item Gabrielle Allen -- National Center for Supercomputing Applications
\item Emily Chen -- University of Illinois at Urbana-Champaign
\item Neil Chue Hong -- U.K. Software Sustainability Institute
\item Ray Idaszak -- RENCI, University of North Carolina at Chapel Hill
\item Iain Larmou -- Engineering and Physical Sciences Research Council
\item Bernie Randles -- University of California, Los Angeles
\item Dan Sellars -- Canarie
\item Fraser Watson -- National Solar Observatory
\end{itemize}

\subsection{Summary of Discussion}

The following summary of the group’s discussion represents the Useful Metrics for Scientific Software working group’s discussion during the WSSSPE3 workshop. The group discussion began by agreeing on the common purpose of creating a set of guidance giving examples of specific metrics for the success of scientific software in use, why they were chosen, what they are useful to measure, and any challenges and pitfalls; then publish this as a white paper.  The group discussed many questions related to useful metrics for scientific software as follows: 

\begin{itemize}

\item
Is there a common set of metrics, that can be filtered in some way

\begin{itemize}
\item
        Does this create a large cost
\end{itemize}

\item
Can we fit metrics into a common template (i.e. for collection, for description)

\item
Which would be the most useful ones

\begin{itemize}
\item
        Which ones would be most useful for each stakeholder
\end{itemize}

\item
Which ones are the most helpful, and how would we assess this

\item
How do you monitor

\begin{itemize}
\item
        Self-checking - if monitoring is done in the open, then people will call out cheats
\end{itemize}

\item
Should this be published with the software metadata

\begin{itemize}
\item
        This would make it easier for public to see the metadata

\item
        However, there is no commonly used standard (DOAP is a good standard but not widely adopted) 

\item
        The Open Directory Project (ODP) metadata is available for UK infrastructure
\end{itemize}

\item
Intersection of most useful and easiest to collect should be explored

\item
How can students/curricula be used as part of a solution

\item
Number of users could be affected by other metrics e.g. by accessibility

\item
Assume metrics are collected properly, but guidance should be provided none-the-less

\item
Continuum for each metric

\begin{itemize}
\item
        Ideal situation is the absolute minimum, so that people can decide on their own what the cost versus usefulness tipping point is
\end{itemize}

\item
Maturity plays a part

\begin{itemize}
\item
        Consider different metrics brackets for different maturity levels
\end{itemize}

\item
What are we using metrics for

\begin{itemize}
\item
        What software should I use if I have a choice

\item
        Where should funders place funding for best impact (e.g. funding two-star software versus three-star) and where there are gaps

\item
        How to promote reduction of code proliferation

\item
        Metrics used for software panels to provide information

\item
        Metrics used for finding problems in their systems

\end{itemize}

\item
Can we use metrics to help people identify the best codes as part of a community effort

\end{itemize}

\smallskip
\noindent
Next, a roadmap for how to proceed was discussed including creating a set of milestones and tasks as follows:

\begin{itemize}
\item
Can we create a roadmap and milestones for this activity

\item
Need to come up with a set of tasks

\item
Go to NSF Software Infrastructure for Sustained Innovation (SI2) projects asking them what metrics they defined, and how useful they were

\begin{itemize}
\item
        Milestone: Create report which assesses the metrics that SI2 projects used

\begin{itemize}
\item
                Ask SI2 PIs to say what metrics they said they would use (copied from proposal)

\item
                Ask SI2 PIs what numbers they reported

\item
                Ask SI2 PIs what they would have changed

\item
                A UIUC student on the project will work on this
\end{itemize}

\item
        Tentatively aim for March 2016
\end{itemize}

\item
Do something similar for UK SFTF and TRDF software projects to ask them what would be useful metrics to report; also eCSE projects

\begin{itemize}
\item
        Compare these to understand if there were any implications for including metrics
\end{itemize}

\item
Collaboratively create plan and documentation for doing this

\begin{itemize}
\item
        Give some examples from group members projects, and aim to build out some of the measurement continuum

\item
        Road-test at the WSSSPE4 meeting
\end{itemize}

\item
Collect the various frameworks together and do a comparison summary

\end{itemize}

\smallskip
\noindent
The idea was put forth for the group to interact with the organizing committee of the 2016 NSF Software Infrastructure for Sustained Innovation (SI2) PI workshop in order to email out a software metrics survey to all SI2 and related awardees as a targeted and relevant set of stakeholders.  This survey would be created by one of the student group members.  Similarly, it was suggested that a software metrics survey be sent to the UK SFTF and TRDF software projects to ask them what metrics would be useful to report.  The remainder of the discussion focused mainly on the creation of a white paper on this topic.  This resulted in a paper outline and writing assignments with the goal of publishing in venues including WSSSPE4, IEEE CISE, or JORS.



\subsection{Description of Opportunity, Challenges, and Obstacles}

The following opportunies, challenges, and obstacles were discussed:

\begin{itemize}
\item
Metrics are important for:

\begin{itemize}
\item
        Tenure and promotion

\item
        Scientific impact

\item
        Discovery

\item
        Reducing duplication

\item
        Basis for potential industrial interest in adopting software

\item
        Make case for funding
\end{itemize}

\item
No commonly-used standard for collecting or presenting metrics

\item
We don’t know if there is a common set of metrics

\item
We have to persuade projects that it is useful to collect metrics

\end{itemize}



\subsection{Key Next Steps}

The following next steps were discussed:

\begin{itemize}
\item
Skype phone call to coordinate shortly after the conclusion of the WSSSPE3 workshop

\item
Get started on IRB at University of Illinois Urbana-Champaign in anticipation of SI2 project survey (may need more thought into survey)

\item
Get started on white paper and associated survey

\end{itemize}



\subsection{Plan for Future Organization}

The following plan for future organization was discussed:

\begin{itemize}
\item
Our group has created a white paper outline with sections assigned to the above individuals, plus see Section 2 response above for timeline

\item
Organizing coordinating phone calls

\end{itemize}




\subsection{What Else is Needed?}

The following list of what else is needed was discussed:

\begin{itemize}
\item
IRB approval/exemption needed for surveys, collecting data

\item
Coordination with 2016 NSF SI2 PI workshop organizing committee to possibly piggyback on this event to offer survey to attendees in advance

\item
Coordination (mail communication, info page etc), via WSSSPE github or?

\end{itemize}



\subsection{Key Milestones and Responsible Parties}

The following items were discussed as a roadmap for the production of a white paper:

\begin{enumerate}
\item
October – November 2015: IRB paperwork as appropriate completed (Gabrielle Allen and Emily Chen)

\item
October – December 2015: Draft white paper sections 1-3 (the paper outline has initial writing assignments)

\item
October – December 2015: Run surveys and collect information

\begin{enumerate}
\item
        Piggy back on planning for 2016 NSF SI2 PIs meeting to be held Feb 16-17, 2016
\end{enumerate}

\item
January – February 2016: Analyze results of data collection from projects

\item
March – April 2016: Draft sections 4-7 of the white paper

\item
May 2016: Draft section 8-9 of the white paper

\item
May – June 2016: Get initial feedback from members of the community and revise

\item
Est. July 2016: By time of next CFP for WSSSPE have complete draft of white paper

\item
Est. Sept – Oct 2016: Responses to white paper submitted to WSSSPE4

\end{enumerate}


\subsection{Description of Funding Needed}

Funding needs were not discussed in this working group and it was thought that this could potentially be revisited down the road.



